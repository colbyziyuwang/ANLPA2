{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to update parent_folder and colab_base as you see fit\n",
    "\n",
    "Download Ollama first to access llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global paths for both local (Mac) and Google Colab\n",
    "PARENT_FOLDER = \"/Users/colbywang/Google Drive/我的云端硬盘/Advanced NLP/Assignments/data files/organized/\"\n",
    "COLAB_BASE = \"/content/gdrive/MyDrive/Assignments/Advanced NLP/Assignments/data files/organized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to predict stock percentage change\n",
    "        self.fc = nn.Linear(hidden_size, 7)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # LSTM forward pass\n",
    "        output, hidden = self.lstm(x, hidden)  \n",
    "        \n",
    "        # Take the last output step for prediction\n",
    "        output = self.fc(output[:, -1, :])  \n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize hidden and cell states with zeros\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h_0, c_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colbywang/Desktop/ANLPA2/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load FinBERT model and tokenizer\n",
    "model_name = \"yiyanghkust/finbert-pretrain\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_average_embedding(sentences):\n",
    "    \"\"\"Compute and average sentence embeddings using FinBERT.\"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        # Forward pass to get hidden states\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Extract [CLS] token embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "\n",
    "    # Convert list to NumPy array and compute the mean embedding\n",
    "    avg_embedding = np.mean(np.array(embeddings), axis=0)\n",
    "    \n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.packs.sentence_window_retriever import SentenceWindowRetrieverPack as SentenceWindowRetriever\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# ✅ Load the LLM Model\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2\",\n",
    "    context_window=4096,\n",
    "    request_timeout=600.0,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# ✅ Load the embedding model\n",
    "embedding_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# ✅ Configure Settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_model\n",
    "\n",
    "# ✅ Load documents\n",
    "file_path = \"2001_0000912057-01-006039.txt\"\n",
    "docs = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "\n",
    "# ✅ Create Node Parser with Sentence Window\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=1,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n",
    "\n",
    "# ✅ Process nodes from documents\n",
    "nodes = node_parser.get_nodes_from_documents(docs)\n",
    "\n",
    "# ✅ Create Vector Store Index\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# ✅ Create Retriever\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=3\n",
    ")\n",
    "\n",
    "# ✅ Create Query Engine\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "\n",
    "# ✅ Function to run queries\n",
    "def run_rag_query(query_text):\n",
    "    response = query_engine.query(query_text)\n",
    "    print(\"\\n🔹 Query:\", query_text)\n",
    "    print(\"\\n🔹 RAG Response:\")\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "# ✅ Example usage\n",
    "query = \"What are the top 3-5 material risk factors highlighted in this 10-K?\"\n",
    "response = run_rag_query(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colbywang/Desktop/ANLPA2/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.packs.sentence_window_retriever import SentenceWindowRetrieverPack as SentenceWindowRetriever\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# ✅ Load the LLM Model\n",
    "llm = Ollama(\n",
    "    model=\"llama3.2\",\n",
    "    context_window=4096,\n",
    "    request_timeout=600.0,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# ✅ Load the embedding model\n",
    "embedding_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# ✅ Configure Settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_model\n",
    "\n",
    "# ✅ Create Node Parser with Sentence Window (Used in Function)\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=1,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n",
    "\n",
    "def run_rag_pipeline(file_path, query_text):\n",
    "    \"\"\"\n",
    "    Runs the RAG pipeline for a given document file path and query.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the 10-K or DEF 14A file.\n",
    "        query_text (str): The query to ask the LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The retrieved response from the document.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Load document\n",
    "    docs = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "\n",
    "    # ✅ Process nodes from document\n",
    "    nodes = node_parser.get_nodes_from_documents(docs)\n",
    "\n",
    "    # ✅ Create Vector Store Index\n",
    "    index = VectorStoreIndex(nodes)\n",
    "\n",
    "    # ✅ Create Retriever\n",
    "    retriever = index.as_retriever(\n",
    "        similarity_top_k=3\n",
    "    )\n",
    "\n",
    "    # ✅ Create Query Engine\n",
    "    query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "\n",
    "    # ✅ Run the query\n",
    "    response = query_engine.query(query_text)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_file_path(colab_path):\n",
    "    \"\"\"\n",
    "    Converts a file path from Google Drive (Colab) to a local path.\n",
    "\n",
    "    Args:\n",
    "        colab_path (str): The file path from Google Drive in Colab.\n",
    "\n",
    "    Returns:\n",
    "        str: The equivalent local path.\n",
    "    \"\"\"\n",
    "    local_path = colab_path.replace(COLAB_BASE, PARENT_FOLDER, 1)\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 397 files and testing on 100 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_folder = os.path.join(PARENT_FOLDER, \"stock-data\")\n",
    "csv_files = [file for file in os.listdir(csv_folder) if file.endswith(\".csv\")]\n",
    "\n",
    "# Train/Test split\n",
    "train_files = csv_files[:int(0.8 * len(csv_files))]\n",
    "test_files = csv_files[int(0.8 * len(csv_files)):]\n",
    "print(f\"Training on {len(train_files)} files and testing on {len(test_files)} files.\")\n",
    "\n",
    "# Modify train_files and test_files to store file paths\n",
    "train_files = [os.path.join(csv_folder, file) for file in train_files]\n",
    "test_files = [os.path.join(csv_folder, file) for file in test_files]\n",
    "\n",
    "def sample_a_row_with_10K_DEF14A(stock_file, num_trading_days=6):\n",
    "    \"\"\"\n",
    "    Randomly selects a row where either a 10-K or DEF 14A filing exists\n",
    "    and returns the row along with the next `num_trading_days` valid trading days.\n",
    "    \"\"\"\n",
    "    # Load the stock data CSV file\n",
    "    stock_data = pd.read_csv(stock_file, parse_dates=[\"Date\"])\n",
    "    stock_data.set_index(\"Date\", inplace=True)  # Ensure Date is the index\n",
    "    stock_data.sort_index(inplace=True)  # Sort by Date to ensure correctness\n",
    "\n",
    "    # First determine randomly whether to sample 10-K or DEF 14A\n",
    "    sample_10K = random.choice([True, False])\n",
    "\n",
    "    # Get the sample row\n",
    "    if sample_10K:\n",
    "        filtered_df = stock_data[stock_data[\"10-K\"] != \"0\"]  # Ensure paths are considered\n",
    "    else:\n",
    "        filtered_df = stock_data[stock_data[\"DEF 14A\"] != \"0\"]\n",
    "\n",
    "    # If no matching row found, return None\n",
    "    if filtered_df.empty:\n",
    "        print(\"⚠️ No matching rows found.\")\n",
    "        return None\n",
    "\n",
    "    # Randomly sample a row\n",
    "    sampled_row = filtered_df.sample(1)\n",
    "    sampled_date = sampled_row.index[0]\n",
    "\n",
    "    # Find the position of this row in the stock DataFrame\n",
    "    sampled_idx = stock_data.index.get_loc(sampled_date)\n",
    "\n",
    "    # Select the next `num_trading_days` rows after sampled index\n",
    "    future_dates = stock_data.index[sampled_idx: sampled_idx + num_trading_days + 1]  # +1 to include sampled row\n",
    "    selected_rows = stock_data.loc[future_dates]\n",
    "\n",
    "    return selected_rows\n",
    "\n",
    "def get_batch_data(stock_file, num_trading_days=6, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generates a batch of training data from a stock data CSV file.\n",
    "    \"\"\"\n",
    "    # initialize lists to store features and target\n",
    "    features_list = []\n",
    "    target_list = []\n",
    "\n",
    "    # Loop through the batch size\n",
    "    for _ in tqdm(range(batch_size), desc=\"Processing batch\"):\n",
    "        # Sample a row with 10-K or DEF 14A\n",
    "        stock_data = sample_a_row_with_10K_DEF14A(stock_file, num_trading_days)\n",
    "\n",
    "        # **If no valid data is found, skip training**\n",
    "        if stock_data is None or stock_data.empty:\n",
    "            print(\"⚠️ No valid row found for training. Skipping...\")\n",
    "            return None\n",
    "\n",
    "        # **Extract input features (ignore categorical columns)**\n",
    "        features = stock_data.drop(columns=[\"10-K\", \"DEF 14A\", \"Change\"]).values\n",
    "        target = stock_data[\"Percentage Change\"].values\n",
    "\n",
    "        # **Enhance features with RAG embeddings**\n",
    "        first_row = stock_data.iloc[0]  # First row contains the filing path\n",
    "\n",
    "        # Ensure the values are strings before checking\n",
    "        ten_k_path = str(first_row[\"10-K\"]) if not pd.isna(first_row[\"10-K\"]) else \"0\"\n",
    "        def_14a_path = str(first_row[\"DEF 14A\"]) if not pd.isna(first_row[\"DEF 14A\"]) else \"0\"\n",
    "\n",
    "        # **Check if there is a valid filing path**\n",
    "        if ten_k_path != \"0\":\n",
    "            file_path = switch_file_path(ten_k_path)\n",
    "            response = run_rag_pipeline(file_path, \n",
    "                \"Summarize the most critical financial risks and uncertainties outlined in this 10-K filing.\"\n",
    "            )\n",
    "        elif def_14a_path != \"0\":\n",
    "            file_path = switch_file_path(def_14a_path)\n",
    "            response = run_rag_pipeline(file_path, \n",
    "                \"Summarize the key executive compensation decisions and governance changes disclosed in this DEF 14A filing.\"\n",
    "            )\n",
    "        else:\n",
    "            response = \"\"  # No filing path available, return empty response\n",
    "\n",
    "        # **Convert RAG response into embeddings**\n",
    "        if response:\n",
    "            # **Convert RAG response into embeddings**\n",
    "            response_text = str(response)  # Convert response object to string\n",
    "            \n",
    "            # Ensure response is processed correctly\n",
    "            if hasattr(response, 'response'):  # If response has a .response attribute\n",
    "                response_text = response.response  \n",
    "            elif hasattr(response, 'text'):  # If response has a .text attribute\n",
    "                response_text = response.text  \n",
    "            \n",
    "            rag_sentences = response_text.split(\".\")  # Split into sentences\n",
    "            rag_embedding = get_average_embedding(rag_sentences)  # (768,)\n",
    "            rag_embedding = np.tile(rag_embedding, (features.shape[0], 1))  # Repeat embedding for each row\n",
    "\n",
    "        else:\n",
    "            rag_embedding = np.zeros((features.shape[0], 768))  # Use zero vector if no RAG data\n",
    "\n",
    "        # **Concatenate RAG embedding with features**\n",
    "        features = np.hstack((features, rag_embedding))\n",
    "\n",
    "        # **Normalize the features and target**\n",
    "        features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-8)  # Avoid division by zero\n",
    "        target = (target - target.mean()) / (target.std() + 1e-8)\n",
    "\n",
    "        # **Convert to PyTorch tensors**\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)  # (batch, seq_len, input_size)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        # Append to the lists\n",
    "        features_list.append(features_tensor)\n",
    "        target_list.append(target_tensor)\n",
    "    \n",
    "    # Stack the tensors along the batch dimension\n",
    "    features_batch = torch.cat(features_list, dim=0)\n",
    "    target_batch = torch.cat(target_list, dim=0)\n",
    "\n",
    "    return features_batch, target_batch\n",
    "\n",
    "def train(LSTM_Model, stock_file, optimizer, num_trading_days=6):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model on a randomly sampled row from the stock data CSV file.\n",
    "    \n",
    "    Args:\n",
    "        LSTM_Model: The LSTM model.\n",
    "        stock_file: Path to the stock data CSV file.\n",
    "        optimizer: The optimizer for training the model.\n",
    "        num_trading_days: Number of past trading days used as input.\n",
    "\n",
    "    Returns:\n",
    "        loss_value: The computed training loss.\n",
    "    \"\"\"\n",
    "    # **Get a batch of training data**\n",
    "    features_batch, target_batch = get_batch_data(stock_file, num_trading_days)\n",
    "\n",
    "    # **If no valid data is found, skip training**\n",
    "    if features_batch is None or target_batch is None:\n",
    "        return None\n",
    "    \n",
    "    # **Initialize hidden states**\n",
    "    hidden = LSTM_Model.init_hidden(features_batch.size(0))\n",
    "    hidden = tuple(h.to(device) for h in hidden)\n",
    "\n",
    "    # **Forward pass**\n",
    "    output, hidden = LSTM_Model(features_batch, hidden)\n",
    "\n",
    "    # **Compute loss**\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(output, target_batch)\n",
    "\n",
    "    # **Backpropagation**\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch:   0%|          | 0/32 [13:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# **Iterate Through Stock Files**\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock_file \u001b[38;5;129;01min\u001b[39;00m train_files:\n\u001b[0;32m---> 41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_LSTM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trading_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trading_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# If training was successful\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[24], line 155\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(LSTM_Model, stock_file, optimizer, num_trading_days)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mTrains the LSTM model on a randomly sampled row from the stock data CSV file.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    loss_value: The computed training loss.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# **Get a batch of training data**\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m features_batch, target_batch \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trading_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# **If no valid data is found, skip training**\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m target_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[24], line 91\u001b[0m, in \u001b[0;36mget_batch_data\u001b[0;34m(stock_file, num_trading_days, batch_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ten_k_path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     90\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m switch_file_path(ten_k_path)\n\u001b[0;32m---> 91\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_rag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSummarize the most critical financial risks and uncertainties outlined in this 10-K filing.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m def_14a_path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     95\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m switch_file_path(def_14a_path)\n",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m, in \u001b[0;36mrun_rag_pipeline\u001b[0;34m(file_path, query_text)\u001b[0m\n\u001b[1;32m     52\u001b[0m nodes \u001b[38;5;241m=\u001b[39m node_parser\u001b[38;5;241m.\u001b[39mget_nodes_from_documents(docs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# ✅ Create Vector Store Index\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# ✅ Create Retriever\u001b[39;00m\n\u001b[1;32m     58\u001b[0m retriever \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[1;32m     59\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     60\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:76\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Settings\u001b[38;5;241m.\u001b[39membed_model\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/indices/base.py:77\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m---> 77\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:310\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content_nodes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome nodes are missing content, skipping them...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:279\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:244\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m         node_without_embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         index_struct\u001b[38;5;241m.\u001b[39madd_node(node_without_embedding, text_id\u001b[38;5;241m=\u001b[39mnew_id)\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_docstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_without_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# NOTE: if the vector store keeps text,\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# we only need to add image and index nodes\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node, new_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nodes_batch, new_ids):\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/storage/docstore/keyval_docstore.py:219\u001b[0m, in \u001b[0;36mKVDocumentStore.add_documents\u001b[0;34m(self, docs, allow_update, batch_size, store_text)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add a document to the store.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n\u001b[0;32m--> 219\u001b[0m node_kv_pairs, metadata_kv_pairs, ref_doc_kv_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_kv_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_text\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kvstore\u001b[38;5;241m.\u001b[39mput_all(\n\u001b[1;32m    224\u001b[0m     node_kv_pairs,\n\u001b[1;32m    225\u001b[0m     collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_collection,\n\u001b[1;32m    226\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kvstore\u001b[38;5;241m.\u001b[39mput_all(\n\u001b[1;32m    230\u001b[0m     metadata_kv_pairs,\n\u001b[1;32m    231\u001b[0m     collection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata_collection,\n\u001b[1;32m    232\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/storage/docstore/keyval_docstore.py:186\u001b[0m, in \u001b[0;36mKVDocumentStore._prepare_kv_pairs\u001b[0;34m(self, nodes, allow_update, store_text)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (TextNode, Document)) \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mref_doc_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     ref_doc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_ref_doc_info(node\u001b[38;5;241m.\u001b[39mref_doc_id) \u001b[38;5;129;01mor\u001b[39;00m RefDocInfo()\n\u001b[1;32m    182\u001b[0m (\n\u001b[1;32m    183\u001b[0m     node_kv_pair,\n\u001b[1;32m    184\u001b[0m     metadata_kv_pair,\n\u001b[1;32m    185\u001b[0m     ref_doc_kv_pair,\n\u001b[0;32m--> 186\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_kv_pairs_for_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_doc_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_kv_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     node_kv_pairs\u001b[38;5;241m.\u001b[39mappend(node_kv_pair)\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/llama_index/core/storage/docstore/keyval_docstore.py:119\u001b[0m, in \u001b[0;36mKVDocumentStore._get_kv_pairs_for_insert\u001b[0;34m(self, node, ref_doc_info, store_text)\u001b[0m\n\u001b[1;32m    116\u001b[0m     metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref_doc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mref_doc_id\n\u001b[1;32m    118\u001b[0m     metadata_kv_pair \u001b[38;5;241m=\u001b[39m (node_key, metadata)\n\u001b[0;32m--> 119\u001b[0m     ref_doc_kv_pair \u001b[38;5;241m=\u001b[39m (node\u001b[38;5;241m.\u001b[39mref_doc_id, \u001b[43mref_doc_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     metadata_kv_pair \u001b[38;5;241m=\u001b[39m (node_key, metadata)\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/dataclasses_json/api.py:73\u001b[0m, in \u001b[0;36mDataClassJsonMixin.to_dict\u001b[0;34m(self, encode_json)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, encode_json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Json]:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/dataclasses_json/core.py:437\u001b[0m, in \u001b[0;36m_asdict\u001b[0;34m(obj, encode_json)\u001b[0m\n\u001b[1;32m    435\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencode_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_json\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend((field\u001b[38;5;241m.\u001b[39mname, value))\n\u001b[1;32m    443\u001b[0m result \u001b[38;5;241m=\u001b[39m _handle_undefined_parameters_safe(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mobj, kvs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(result),\n\u001b[1;32m    444\u001b[0m                                            usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/dataclasses_json/core.py:453\u001b[0m, in \u001b[0;36m_asdict\u001b[0;34m(obj, encode_json)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# enum.IntFlag and enum.Flag are regarded as collections in Python 3.11, thus a check against Enum is needed\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Collection) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, Enum)):\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# encoding of generics primarily relies on concrete types while decoding relies on type annotations. This makes\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# applying encoders/decoders from global configuration inconsistent.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _has_encoder_in_global_config(\u001b[38;5;28mtype\u001b[39m(obj)):\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/dataclasses_json/core.py:453\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# enum.IntFlag and enum.Flag are regarded as collections in Python 3.11, thus a check against Enum is needed\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Collection) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, Enum)):\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43m_asdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_json\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# encoding of generics primarily relies on concrete types while decoding relies on type annotations. This makes\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# applying encoders/decoders from global configuration inconsistent.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _has_encoder_in_global_config(\u001b[38;5;28mtype\u001b[39m(obj)):\n",
      "File \u001b[0;32m~/Desktop/ANLPA2/rag/lib/python3.11/site-packages/dataclasses_json/core.py:452\u001b[0m, in \u001b[0;36m_asdict\u001b[0;34m(obj, encode_json)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m((_asdict(k, encode_json\u001b[38;5;241m=\u001b[39mencode_json),\n\u001b[1;32m    449\u001b[0m                  _asdict(v, encode_json\u001b[38;5;241m=\u001b[39mencode_json)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    450\u001b[0m                 obj\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# enum.IntFlag and enum.Flag are regarded as collections in Python 3.11, thus a check against Enum is needed\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCollection\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, Enum)):\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_asdict(v, encode_json\u001b[38;5;241m=\u001b[39mencode_json) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# encoding of generics primarily relies on concrete types while decoding relies on type annotations. This makes\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# applying encoders/decoders from global configuration inconsistent.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py:1281\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__instancecheck__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__, attr, val)\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(obj))\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Checkpoint Folder if it doesn't exist\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Define Model & Optimizer\n",
    "input_size = 785  # (Stock prices & Volume) + (Yield) + (CPI and Inflation) + (RAG embedding)\n",
    "hidden_size = 64\n",
    "num_epochs = 100  # Change this for more training\n",
    "num_trading_days = 6  # Lookback window\n",
    "\n",
    "# ✅ Initialize Model (Load from checkpoint if exists)\n",
    "model_LSTM = StockLSTM(input_size, hidden_size).to(device)\n",
    "\n",
    "# Load from checkpoint if available\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"lstm_final.pth\")\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model_LSTM.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"🔍 Loaded model checkpoint: {checkpoint_path}\")\n",
    "\n",
    "# ✅ Define Optimizer\n",
    "optimizer = torch.optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
    "\n",
    "# ✅ Training Loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n🚀 Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    # **Iterate Through Stock Files**\n",
    "    for stock_file in train_files:\n",
    "        loss = train(model_LSTM, stock_file, optimizer, num_trading_days=num_trading_days)\n",
    "        \n",
    "        if loss is not None:  # If training was successful\n",
    "            epoch_loss += loss\n",
    "            num_samples += 1\n",
    "        \n",
    "        # Save every iteration\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"lstm_final.pth\")\n",
    "        torch.save(model_LSTM.state_dict(), checkpoint_path)\n",
    "        print(f\"📌 Model saved: {checkpoint_path}\")\n",
    "\n",
    "    # **Compute Average Loss for Epoch**\n",
    "    avg_loss = epoch_loss / max(num_samples, 1)  # Avoid division by zero\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"✅ Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# ✅ Final Model Save\n",
    "final_model_path = os.path.join(checkpoint_dir, \"lstm_final.pth\")\n",
    "torch.save(model_LSTM.state_dict(), final_model_path)\n",
    "print(f\"🎯 Training Completed! Final model saved: {final_model_path}\")\n",
    "\n",
    "# ✅ Plot the Loss Curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(losses, label=\"Training Loss\", color='blue')\n",
    "plt.title(\"LSTM Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
